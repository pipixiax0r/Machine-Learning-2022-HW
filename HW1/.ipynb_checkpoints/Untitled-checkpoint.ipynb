{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbaa6d1-11a8-41c9-b840-6fb1db9a82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9879412a-10a3-4b86-a3e4-756e995bf1b4",
   "metadata": {},
   "source": [
    "# Some Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0432ee58-eb4b-40ed-a912-da8afb051447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed): \n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    # if determinsitic is True, cause cuDNN to  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa1d1671-d67b-4b2f-849c-119b75c34aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f061c-2fbc-4bc8-8431-4f3aaef197dd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cae8f56-f8a9-4b1d-929b-acf240758b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fbf5e2-4b62-49b6-8501-e1676bcac0a5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6020e7cb-ba1c-497d-bb1b-6cddf720f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FNN, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions. \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Linear(16, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e0a9d-53ea-4fd0-b83f-3c452793bee1",
   "metadata": {},
   "source": [
    "# Feature Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f77cc5-115d-44d4-8767-8cba4d28c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
    "    '''Selects useful features to perform regression'''\n",
    "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
    "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
    "\n",
    "    if select_all:\n",
    "        feat_idx = list(range(raw_x_train.shape[1]))\n",
    "    else:\n",
    "        feat_idx = [0,1,2,3,4] # TODO: Select suitable feature columns.\n",
    "        \n",
    "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e41d42-bb70-4bed-9479-e4a7a3f913ed",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b11bec-061c-4f44-8d4a-05985b5e85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "\n",
    "def trainer(train_loader, valid_loader, model, config):\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models')\n",
    "    \n",
    "    device = torch.device(config['device'])\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], 2**64, 0, 0\n",
    "    \n",
    "    epoch_pbar = tqdm(range(n_epochs), position=0)\n",
    "    for epoch in epoch_pbar:\n",
    "        model.train()\n",
    "        loss_record = []\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "            \n",
    "            loss_record.append(loss.detach().item())\n",
    "\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "        \n",
    "        epoch_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "        epoch_pbar.set_postfix({'train_loss': mean_train_loss, 'valid_loss': mean_valid_loss})\n",
    "        \n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path'])\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "        \n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('Trining end.')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4617a26c-4c26-4d1f-b585-d9f8f8638ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\t'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'seed': 233333,\n",
    "    'select_all': True,\n",
    "    'valid_ratio': 0.2,\n",
    "    'n_epochs': 3000,\n",
    "    'batch_size':256,\n",
    "    'weight_decay':0.1,\n",
    "    'lr': 1e-3,\n",
    "    'early_stop': 400,\n",
    "    'save_path': './models/model.ckpt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2920af4-9de6-4ff8-9232-e6df1060f90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size: (2160, 118)\n",
      "valid_data size: (539, 118)\n",
      "test_data size: (1078, 117)\n"
     ]
    }
   ],
   "source": [
    "set_seed(config['seed'])\n",
    "\n",
    "train_data, test_data = pd.read_csv('./covid.train.csv').values, pd.read_csv('./covid.test.csv').values\n",
    "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
    "print(f'train_data size: {train_data.shape}')\n",
    "print(f'valid_data size: {valid_data.shape}')\n",
    "print(f'test_data size: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d8add9-8a5d-489a-b2a4-8164a864a15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 117\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, x_text, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
    "print(f'number of features: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132c412f-89d1-470c-b9ca-85e0183ca1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = MyDataset(x_valid, y_valid), MyDataset(x_train, y_train), MyDataset(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60cc8883-ab9c-4c00-9c71-d57df2a1fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f4f9ee-e27c-496f-8a47-c6fec78aec6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2365/3000]:  79%|███████████   | 2364/3000 [01:12<00:19, 32.47it/s, train_loss=1.24, valid_loss=1.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trining end.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = FNN(input_dim=x_train.shape[1]).to(torch.device(config['device']))\n",
    "trainer(train_loader, valid_loader, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6ac2f27-7742-4a25-84bb-5df047a3d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11280), started 1:22:49 ago. (Use '!kill 11280' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-afe63730d633a762\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-afe63730d633a762\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdce3d0c-8a42-44b6-84de-8b772c85fb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FNN(input_dim=x_train.shape[1]).to(config['device'])\n",
    "model.load_state_dict(torch.load(config['save_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df7f19b3-4f10-4bc1-a1c6-bdabd50fd0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for x in tqdm(test_loader):\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "            preds.append(pred.detach().cpu())\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98c21874-1d3f-4c36-968f-ef55cc1de431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 556.94it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = predict(test_loader, model, config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2132100b-3973-4c49-895f-d901f05ff711",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(preds, columns=['tested_positive']).to_csv('./predict/predict2.csv', index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e026267ffe3239a549cbe25ef3aab0f7c1da1b70fb1865e60419e472adda2c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
